<!doctype html>
<html lang="en" ">
    <head>
        <link rel="stylesheet" href="../css/bootstrap.min.css">
        <script src="../js/bootstrap.bundle.min.js"></script>
        <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.7.0/css/all.css" integrity="sha384-lZN37f5QGtY3VHgisS14W3ExzMWZxybE1SJSEsQp9S+oqd12jhcu+A56Ebc1zFSJ" crossorigin="anonymous">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <script>
         (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
             (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
                                  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
         })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

         ga('create', 'UA-69760518-1', 'auto');
         ga('send', 'pageview');
        </script>
        <title>A Case Study on the Effectiveness of LLMs in Verification with Proof Assistants</title>

    </head>
    <body>
        <main role="main">
            <div class="container">
    <div class="row col-sm-10 page-header">
        <h1>A Case Study on the Effectiveness of LLMs in Verification with Proof Assistants</h1>
        <p class="lead">by Barış Bayazıt, Yao Li, Xujie Si</p>
        <p class="lead">1st International Workshop on Language Models and Programming Languages, LMPL 2025</p>
        
        <a href="https://www.youtube.com/live/Aa-gILVLWjg?si=Y2LufyzVkE-0NNMZ&t=24730" target="_blank" class="btn btn-default btn-sm"><i class="fa fa-video"></i>&nbsp;Talk</a>
        
        
        <a href="https://doi.org/10.1145/3759425.3763391" target="_blank" class="btn btn-default btn-sm"><i class="fa fa-file-alt"></i>&nbsp;Paper
            
            (Open Access)
            
        </a>
        
        
        <a href="https://arxiv.org/pdf/2508.18587" target="_blank" class="btn btn-default btn-sm"><i class="far fa-file-alt"></i>&nbsp;Pre-print</a>
        
        
        <a href="https://doi.org/10.5281/zenodo.16939067" target="_blank" class="btn btn-default btn-sm"><i class="fas fa-code"></i>&nbsp;Artifact</a>
        
    </div>
    <div class="row col-sm-10">
        <p>Large language models (LLMs) can potentially help with verification using proof
assistants by automating proofs. However, it is unclear how effective LLMs are
in this task. In this paper, we perform a case study based on two mature Rocq
projects: the hs-to-coq tool and Verdi. We evaluate the effectiveness of LLMs in
generating proofs by both quantitative and qualitative analysis. Our study finds
that: (1) external dependencies and context in the same source file can
significantly help proof generation; (2) LLMs perform great on small proofs but
can also generate large proofs; (3) LLMs perform differently on different
verification projects; and (4) LLMs can generate concise and smart proofs, apply
classical techniques to new definitions, but can also make odd mistakes.</p>
    </div>
</div>

        </main>

        <footer class="text-center">
            Site proudly generated by
            <a href="http://jaspervdj.be/hakyll">Hakyll</a>
        </footer>
    </body>
</html>
