---
title: A Case Study on the Effectiveness of LLMs in Verification with Proof Assistants
authors: Barış Bayazıt, Yao Li, Xujie Si
venue: 1st International Workshop on Language Models and Programming Languages, LMPL 2025
preprint: "https://arxiv.org/pdf/2508.18587"
link: "https://doi.org/10.1145/3759425.3763391"
artifact: "https://doi.org/10.5281/zenodo.16939067"
openaccess: true
featured: true
talk: "https://www.youtube.com/live/Aa-gILVLWjg?si=Y2LufyzVkE-0NNMZ&t=24730"
---

Large language models (LLMs) can potentially help with verification using proof
assistants by automating proofs. However, it is unclear how effective LLMs are
in this task. In this paper, we perform a case study based on two mature Rocq
projects: the hs-to-coq tool and Verdi. We evaluate the effectiveness of LLMs in
generating proofs by both quantitative and qualitative analysis. Our study finds
that: (1) external dependencies and context in the same source file can
significantly help proof generation; (2) LLMs perform great on small proofs but
can also generate large proofs; (3) LLMs perform differently on different
verification projects; and (4) LLMs can generate concise and smart proofs, apply
classical techniques to new definitions, but can also make odd mistakes.
